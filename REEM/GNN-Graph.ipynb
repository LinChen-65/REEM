{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 得到邻接矩阵，train_idx,val_idx,test_idx,以及对应的整个文件"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f83e5b2045cca8f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import radians, sin, cos, arcsin, sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def disN7(lon1, lat1, lon2, lat2):\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    d_lon = lon2 - lon1\n",
    "    d_lat = lat2 - lat1\n",
    "    aa = sin(d_lat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(d_lon / 2) ** 2\n",
    "    bb=sqrt(aa)\n",
    "    c = 2 * arcsin(bb)\n",
    "    r = 6371\n",
    "    return c * r"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc204f4b62feb610"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# load csv"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a402502b1f67009c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def LoadDf(csv_dir):\n",
    "    POI_df = pd.read_csv(csv_dir)\n",
    "    POI_df['racial_segregation_index'] = POI_df['racial_segregation_index'].astype(np.float32)\n",
    "    POI_df['0.5'] = POI_df['0.5'].apply(lambda x:np.fromstring(x[1:-1],sep=' ').astype(np.float32))\n",
    "    POI_df['embedding']=POI_df['embedding'].apply(lambda x:np.array(eval(x)).astype(np.float32))\n",
    "    POI_df['rating'] = POI_df['rating'].apply(lambda x:np.array(eval(x)).astype(np.float32))\n",
    "    return POI_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1e909e8395dea18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_dir = './data/train-dataset/'\n",
    "city = 'New Orleans'\n",
    "datasets_file = 'allembedding&popu&rating'\n",
    "train_dir = os.path.join(dataset_dir,f'{city}/{city}_{datasets_file}_traindata.csv')\n",
    "val_dir = os.path.join(dataset_dir,f'{city}/{city}_{datasets_file}_valdata.csv')\n",
    "test_dir = os.path.join(dataset_dir,f'{city}/{city}_{datasets_file}_testdata.csv')\n",
    "train_df = LoadDf(train_dir)\n",
    "val_df = LoadDf(val_dir)\n",
    "test_df= LoadDf(test_dir)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b709d4fe5fa4e333"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "print('raw shape',train_df.shape,val_df.shape,test_df.shape)\n",
    "duplicates_train_val = train_df.merge(val_df, on='placekey', how='inner')['placekey']\n",
    "duplicates_train_test = train_df.merge(test_df, on='placekey', how='inner')['placekey']\n",
    "duplicates_val_test = test_df.merge(val_df, on='placekey', how='inner')['placekey']\n",
    "duplicates = pd.concat([duplicates_train_val, duplicates_train_test, duplicates_val_test]).unique()\n",
    "train_df = train_df[~train_df['placekey'].isin(duplicates)]\n",
    "val_df = val_df[~val_df['placekey'].isin(duplicates)]\n",
    "test_df = test_df[~test_df['placekey'].isin(duplicates)]\n",
    "print('processed shape',train_df.shape,val_df.shape,test_df.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c507dad67e6970fd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_list = train_df.placekey.tolist()\n",
    "val_list = val_df.placekey.tolist()\n",
    "test_list = test_df.placekey.tolist()\n",
    "all_df = pd.concat([train_df,val_df,test_df]) \n",
    "\n",
    "def assign_split(x):\n",
    "    if x in train_list:\n",
    "        return 2\n",
    "    elif x in val_list:\n",
    "        return 1\n",
    "    elif x in test_list:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "all_df['split'] = all_df['placekey'].apply(assign_split)\n",
    "all_df = all_df.drop_duplicates(subset='placekey', keep='first')\n",
    "all_df = all_df.reset_index(drop=True)\n",
    "\n",
    "all_df.shape,all_df.columns,all_df.iloc[-1].name"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46a0c59cb71e9f5c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GET Adj"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67d658de4d024c1a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Review\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "Neigh_num = 5\n",
    "embedding_matrix = np.vstack(all_df['embedding'].values)\n",
    "similarity_matrix = cosine_similarity(embedding_matrix)\n",
    "adjacency_matrix = np.zeros((len(all_df), len(all_df)), dtype=int)\n",
    "for i in range(len(all_df)):\n",
    "    similarity_vector = similarity_matrix[i]\n",
    "    similarity_vector[i] = -1\n",
    "    nearest_indices = np.argsort(-similarity_vector)[:Neigh_num]\n",
    "    # 更新邻接矩阵\n",
    "    for j in nearest_indices:\n",
    "        adjacency_matrix[i, j] = 1\n",
    "\n",
    "# 保存邻接矩阵到文本文件\n",
    "save_dif = os.path.join(dataset_dir,f'{city}/{city}_review_adj{Neigh_num}.txt')\n",
    "with open(save_dif, 'w') as f:\n",
    "    for i in range(len(all_df)):\n",
    "        for j in range(len(all_df)):\n",
    "            if adjacency_matrix[i, j] == 1:\n",
    "                f.write(f\"{i},{j}\\n\")\n",
    "\n",
    "print(f\"saved in {save_dif}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fa9030670865830"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#rating\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "Neigh_num = 5\n",
    "embedding_matrix = np.vstack(all_df['rating'].values)\n",
    "similarity_matrix = cosine_similarity(embedding_matrix)\n",
    "adjacency_matrix = np.zeros((len(all_df), len(all_df)), dtype=int)\n",
    "for i in range(len(all_df)):\n",
    "    similarity_vector = similarity_matrix[i]\n",
    "    similarity_vector[i] = -1\n",
    "    nearest_indices = np.argsort(-similarity_vector)[:Neigh_num]\n",
    "    # 更新邻接矩阵\n",
    "    for j in nearest_indices:\n",
    "        adjacency_matrix[i, j] = 1\n",
    "\n",
    "# 保存邻接矩阵到文本文件\n",
    "save_dif = os.path.join(dataset_dir,f'{city}/{city}_rating_adj{Neigh_num}.txt')\n",
    "with open(save_dif, 'w') as f:\n",
    "    for i in range(len(all_df)):\n",
    "        for j in range(len(all_df)):\n",
    "            if adjacency_matrix[i, j] == 1:\n",
    "                f.write(f\"{i},{j}\\n\")\n",
    "\n",
    "print(f\"Saved in {save_dif} \")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ca12ee6d24219bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#location\n",
    "def disN7(lon1, lat1, lon2, lat2):\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    d_lon = lon2 - lon1\n",
    "    d_lat = lat2 - lat1\n",
    "    aa = sin(d_lat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(d_lon / 2) ** 2\n",
    "    bb=sqrt(aa)\n",
    "    c = 2 * arcsin(bb)\n",
    "    r = 6371\n",
    "    return c * r\n",
    "\n",
    "Neigh_num = 5\n",
    "\n",
    "adjacency_matrix = np.zeros((len(all_df), len(all_df)), dtype=int)\n",
    "for i,row in all_df.iterrows():\n",
    "    lon,lat = row['longitude'],row['latitude']\n",
    "    dis_series = disN7(lon,lat,all_df['longitude'],all_df['latitude'])\n",
    "    dis_series[i] = float('inf')\n",
    "    nearest_indices = np.argsort(dis_series)[:Neigh_num]\n",
    "    # 更新邻接矩阵\n",
    "    for j in nearest_indices:\n",
    "        adjacency_matrix[i, j] = 1\n",
    "# 保存邻接矩阵到文本文件\n",
    "save_dif = os.path.join(dataset_dir,f'{city}/{city}_location_adj{Neigh_num}.txt')\n",
    "with open(save_dif, 'w') as f:\n",
    "    for i in range(len(all_df)):\n",
    "        for j in range(len(all_df)):\n",
    "            if adjacency_matrix[i, j] == 1:\n",
    "                f.write(f\"{i},{j}\\n\")\n",
    "\n",
    "print(f\"Saved in {save_dif}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abff8ed8982d5ef9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_adjacency_matrix_from_txt(file_path, num_nodes):\n",
    "    adjacency_matrix = np.zeros((num_nodes, num_nodes), dtype=int)\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            i, j = map(int, line.strip().split(','))\n",
    "            adjacency_matrix[i, j] = 1\n",
    "    \n",
    "    return adjacency_matrix\n",
    "\n",
    "\n",
    "num_nodes = len(all_df)\n",
    "adjacency_matrix = read_adjacency_matrix_from_txt(save_dif, num_nodes)\n",
    "adjacency_matrix.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4f670917c0f3a03"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5e85f144362768f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_df['embedding'] = all_df['embedding'].apply(lambda x: ','.join(map(str, x)))\n",
    "all_df['rating'] = all_df['rating'].apply(lambda x: ','.join(map(str, x)))\n",
    "all_df.to_csv(os.path.join(dataset_dir,f'{city}/{city}_GNNGraph.csv'),index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59b8bb0777b36a85"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
