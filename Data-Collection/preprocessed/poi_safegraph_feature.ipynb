{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8e618538293a68",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## pre-process: collect POI's visitor+location+feature from SafeGraph Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ab63d2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "# import pyproj\n",
    "# import geopandas as gpd  \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import tqdm\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d15e919",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## specific city specific time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde9cbaffc6a281",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "specific_area = 'Philadelphia' #ATENTION: change target city name\n",
    "specific_period = '2019'\n",
    "\n",
    "filtdata_dir = '/data/'+specific_area+'/filt_safegraph/'\n",
    "normdata_dir = '/data/'+specific_area+'/normalized_safegraph/'\n",
    "directory = os.path.dirname(filtdata_dir)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "directory = os.path.dirname(normdata_dir)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    \n",
    "cbg_temp = pd.read_csv('/data/' + specific_area + '/' + specific_area +'_cbg_features_group.csv',usecols=['census_block_group'])\n",
    "specific_cbgs = cbg_temp.census_block_group.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b51109",
   "metadata": {},
   "source": [
    "# POI SafeGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c99bec8517d2f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "safegraph_dir = '/data/rawdata/Datasets/SafeGraphDatasets/SafeGraph_new/'\n",
    "files = os.listdir(safegraph_dir)\n",
    "files = [x for x in files if 'patterns-' in x] \n",
    "months = sorted(set([x[9:16] for x in files]))\n",
    "specific_month = [x for x in months if specific_period in x] \n",
    "specific_month_files = sorted([x for x in files for month in specific_month if month in x and 'part' in x]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dbf33c84e28dc1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in specific_month_files: \n",
    "    print(x)\n",
    "    df = pd.read_csv(safegraph_dir+x)\n",
    "    print(df.shape)\n",
    "    specific_filt_poi_df = df[df.poi_cbg.isin(specific_cbgs)] \n",
    "    specific_filt_poi_df['norm'] = specific_filt_poi_df.normalized_visits_by_state_scaling / specific_filt_poi_df.raw_visitor_counts\n",
    "    print(specific_filt_poi_df.shape)\n",
    "    specific_filt_poi_df.to_csv(filtdata_dir+'filt_'+ specific_area + '_' +x,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b553096497146",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " \n",
    "for x in specific_month_files:\n",
    "    print(x)\n",
    "    specific_norm_poi_df = pd.read_csv(filtdata_dir+'filt_'+ specific_area + '_' +x)\n",
    "    for index, row in specific_norm_poi_df.iterrows():\n",
    "        temp_dict = json.loads(row['visitor_home_cbgs'])  \n",
    "        temp_dict = {key: value for key, value in temp_dict.items() if key.isdigit()}\n",
    "        \n",
    "        temp_dict = {key: value for key, value in temp_dict.items() if int(key) in specific_cbgs}\n",
    "        \n",
    "        temp_dict = {key: value * row['norm'] for key, value in temp_dict.items()}\n",
    "        \n",
    "        specific_norm_poi_df.at[index, 'visitor_home_cbgs'] = json.dumps(temp_dict)\n",
    "    \n",
    "    specific_norm_poi_df.to_csv(normdata_dir+'normalized_'+ specific_area + '_' +x,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa3248c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def merge_dicts(dict1, dict2):\n",
    "    merged_dict = dict1.copy()\n",
    "    for key, value in dict2.items():\n",
    "        if key in merged_dict:\n",
    "            merged_dict[key] += value\n",
    "        else:\n",
    "            merged_dict[key] = value\n",
    "    return merged_dict #dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49564f8b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def update_dataframes(df1, df2):\n",
    "    merged_rows = []\n",
    " \n",
    "    for index, row in tqdm.tqdm(df2.iterrows()):\n",
    "        placekey = row['placekey']\n",
    "        if placekey in df1['placekey'].values:\n",
    "            matching_row = df1[df1['placekey'] == placekey].iloc[0].copy() \n",
    "            dict_temp = merge_dicts(matching_row['visitor_home_cbgs'], row['visitor_home_cbgs'])\n",
    "            matching_row['visitor_home_cbgs']= dict_temp\n",
    "            merged_rows.append(matching_row.to_frame().T)\n",
    "        else:\n",
    "            row = pd.DataFrame(row).transpose()\n",
    "            merged_rows.append(row)\n",
    "\n",
    "    merged_df = pd.concat(merged_rows,ignore_index=True)\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411b7b17f4dcf179",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "specific_poi_dfs = pd.DataFrame()\n",
    "for x in specific_month_files: \n",
    "    print(x)\n",
    "\n",
    "    specific_poi_df = pd.read_csv(normdata_dir+'normalized_'+ specific_area + '_' +x,usecols=['placekey','visitor_home_cbgs'])\n",
    "    \n",
    "    specific_poi_df['visitor_home_cbgs'] = specific_poi_df['visitor_home_cbgs'].map(lambda x: json.loads(x)) \n",
    "    specific_poi_df = specific_poi_df[specific_poi_df['visitor_home_cbgs'].apply(lambda x: len(x) > 0)]\n",
    "    specific_poi_df = specific_poi_df.reset_index(drop=True)\n",
    "    \n",
    "    if specific_poi_dfs.empty:\n",
    "        specific_poi_dfs = specific_poi_df\n",
    "    else:\n",
    "    \n",
    "        specific_poi_df_temp = update_dataframes(specific_poi_dfs, specific_poi_df)\n",
    "        \n",
    "        \n",
    "        specific_poi_dfs = specific_poi_df_temp.merge(specific_poi_dfs, on=['placekey'], how='outer',suffixes=('_temp', '_old')) \n",
    "        specific_poi_dfs['visitor_home_cbgs'] = specific_poi_dfs['visitor_home_cbgs_temp'].fillna(specific_poi_dfs['visitor_home_cbgs_old'])\n",
    "        specific_poi_dfs = specific_poi_dfs.drop(['visitor_home_cbgs_old','visitor_home_cbgs_temp'], axis=1)\n",
    "        \n",
    "    print(specific_poi_dfs.shape)\n",
    "    \n",
    "specific_poi_dfs['visitor_home_cbgs'] = specific_poi_dfs.visitor_home_cbgs.map(lambda x: json.dumps(x))\n",
    "specific_poi_dfs.to_csv('/data/'+specific_area+'/'+specific_area+'_poi_visitor.csv',index=False) \n",
    "del specific_poi_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a9445799d0873",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "------------------------  \n",
    "\n",
    "### get poi location and feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943b5f791d71b18a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "poi_list=pd.read_csv('/data/'+specific_area+'/'+specific_area+'_poi_visitor.csv',usecols=['placekey'])\n",
    "print(poi_list.shape)\n",
    "\n",
    "poi_locs = pd.DataFrame(columns=['placekey','latitude','longitude'])\n",
    "for x in specific_month_files:\n",
    "    print(x)\n",
    "    poi_loc_temp = []\n",
    "    poi_loc = pd.read_csv(normdata_dir+'normalized_'+ specific_area + '_' +x,usecols=['placekey','longitude','latitude'])\n",
    "    for index, row in tqdm.tqdm(poi_loc.iterrows()):\n",
    "        if row['placekey'] in poi_list['placekey'].values and row['placekey'] not in poi_locs['placekey'].values:\n",
    "            poi_location = []\n",
    "            poi_location.extend(row)\n",
    "            poi_loc_temp.append(poi_location)\n",
    "    poi_loc_temp = pd.DataFrame(poi_loc_temp, columns=['placekey','latitude','longitude'])\n",
    "    #print(poi_features_temp)\n",
    "    poi_locs = pd.concat([poi_locs, poi_loc_temp], axis=0)\n",
    "\n",
    "print(poi_locs.shape)\n",
    "poi_locs.to_csv('/data/'+specific_area+'/'+specific_area+'_poi_location.csv',index=False)\n",
    "del poi_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c32a5552c1e05a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "poi_features = pd.DataFrame()\n",
    "poi_list=pd.read_csv('/data/'+specific_area+'/'+specific_area+'_poi_visitor.csv',usecols=['placekey'])\n",
    "print(poi_list.shape)\n",
    "for x in specific_month_files:\n",
    "    print(x)\n",
    "    poi_features_temp = []\n",
    "    boston_poi_df = pd.read_csv(normdata_dir+'normalized_'+ specific_area + '_' +x,usecols=['placekey', 'location_name', 'top_category', 'naics_code','poi_cbg'])#any feature you need\n",
    "    for index, row in tqdm.tqdm(boston_poi_df.iterrows()):\n",
    "        if row['placekey'] in poi_list['placekey'].values:\n",
    "            poi_feature = []\n",
    "            poi_feature.extend(row)\n",
    "      \n",
    "            poi_features_temp.append(poi_feature)\n",
    "    poi_features_temp = pd.DataFrame(poi_features_temp, columns=['placekey', 'location_name', 'top_category', 'naics_code','poi_cbg'])\n",
    "  \n",
    "    poi_features = pd.concat([poi_features, poi_features_temp], axis=0)\n",
    "\n",
    "poi_features = poi_features.drop_duplicates()\n",
    "poi_features = poi_features.reset_index(drop=True)\n",
    "poi_features.to_csv('/data/'+specific_area+'/'+specific_area+'_poi_features.csv',index=False) #['placekey', 'location_name', 'top_category', 'naics_code', 'poi_cbg']\n",
    "\n",
    "poi_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "363f587d6aefcc1c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
